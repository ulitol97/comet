---
id: predefined_extractors
title: Pre-defined extractors
---

# Pre-defined extractors

@APP_NAME@ offers some functionality out of the box, as it comes with some
pre-defined extractors ready to be used:

## [List extractor](https://ulitol97.github.io/comet/scaladoc/org/ragna/comet/stream/extractors/list/ListExtractor.html)

Extractor capable of generating a stream of RDF data from an in-memory sequence
of items.

## [File extractor](https://ulitol97.github.io/comet/scaladoc/org/ragna/comet/stream/extractors/file/FileExtractor.html)

Extractor capable of generating a stream of RDF data from a list of Files.

- Each file is expected to contain a single piece of RDF data.
- Uses FS2's Files API.

> Inspired by https://fs2.io/#/getstarted/example

### Additional configurations

#### Charset

- **Purpose**: Charset used in the target files.
- **Default value**: `UTF-8`

## [Kafka extractor](https://ulitol97.github.io/comet/scaladoc/org/ragna/comet/stream/extractors/kafka/KafkaExtractor.html)

Extractor capable of generating a stream of RDF data from an incoming Apache
Kafka stream of items.

### Additional configurations

Being more complex, _KafkaExtractors_ require
a _[KafkaExtractorConfiguration](https://ulitol97.github.io/comet/scaladoc/org/ragna/comet/stream/extractors/kafka/KafkaExtractorConfiguration.html)_
specifying how to reach and operate the Kafka stream, specifically:

#### Mandatory configurations

- <u>topic</u>: Name of the topic from which data will be received

#### Optional configurations

There are plenty of additional settings, the main ones being:

- _server_:
  - Hostname or IP address of the Kafka server broadcasting data.
  - Defaults to `localhost`.
- _port_:
  - Port from which the server is broadcasting data.
  - Defaults to `9092`.
- _groupId_:
  - Group to which the underlying Kafka consumer belongs
  - Defaults to an autogenerated group ID with the app's name and version.

Visit the complete Scaladoc for further information.

